## 7장 강화학습 심화 3: 아타리
### 브레이크아웃 DQN
아타리 브레이크아웃에 적용한 **DQN** 알고리즘은, **컨볼루션 신경망**을 사용하여 게임 화면을 입력으로 받아 행동의 개수대로 큐함수의 값을 출력한다.

공의 속도 정보를 얻기 위하여 4개의 연속된 이미지(히스토리) 를 입력으로 받았는데, 이 때 **프레임 스킵**<sup>Frame skip</sup>을 사용했다.

<br>

### 브레이크아웃 A3C
DQN 알고리즘에서는 샘플들 사이의 상관관계를 깨기 위해서 리플레이 메모리를 사용했었다. 하지만 이 방식은 거대한 메모리를 사용하여 학습하는 것이므로 비효율적이며 학습이 오래 걸린다는 단점이 존재한다.

**A3C**<sup>Asynchronous Advantage Actor-Critic</sup> 알고리즘은 여러 개의 **액터러너**<sup>Actor-Learner</sup>가 각기 다른 환경에서 일정 타임스텝 동안 모은 샘플을 통해 글로벌 신경망을 **비동기적**으로 업데이트하는 방식이다.

<img src=https://user-images.githubusercontent.com/62216628/170973637-4c1494f3-3884-4dde-ad77-f078bed06b32.png width=300px/>
